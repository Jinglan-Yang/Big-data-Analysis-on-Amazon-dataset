{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2 DSC 102 FA23"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In this assignment we will conduct data engineering for the Amazon dataset. It is divided into 2 parts. The extracted features in Part 1 will be used for the Part 2 of assignment, where you train a model (or models) to predict user ratings for a product.\n",
    "\n",
    "We will be using Apache Spark for this assignment. The default Spark API will be DataFrame, as it is now the recommended choice over the RDD API. That being said, please feel free to switch back to the RDD API if you see it as a better fit for the task. We provide you an option to request RDD format to start with. Also you can switch between DataFrame and RDD in your solution. \n",
    "\n",
    "Another newer API is Koalas, which is also avaliable. However, it has constraints and is not applicable to most tasks. Refer to the PA statement for detail."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the following parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-03T18:47:30.022030Z",
     "start_time": "2020-02-03T18:47:30.019499Z"
    }
   },
   "outputs": [],
   "source": [
    "PID = 'U09809880' # your pid, for instance: 'a43223333'\n",
    "INPUT_FORMAT = 'dataframe' # choose a format of your input data, valid options: 'dataframe', 'rdd', 'koalas'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-03T18:50:16.780690Z",
     "start_time": "2020-02-03T18:47:30.263681Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Found pyspark version \"3.3.1\" installed. The pyspark version 3.2 and above has a built-in \"pandas APIs on Spark\" module ported from Koalas. Try `import pyspark.pandas as ps` instead. \n",
      "WARNING:root:'PYARROW_IGNORE_TIMEZONE' environment variable was not set. It is required to set this environment variable to '1' in both driver and executor sides if you use pyarrow>=2.0.0. Koalas will set it for you but it does not work if there is a Spark context already launched.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/11/27 23:02:09 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "/opt/bitnami/spark/python/pyspark/sql/context.py:112: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
      "  warnings.warn(\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading datasets ...Done\n"
     ]
    }
   ],
   "source": [
    "# Boiler plates, do NOT modify\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import getpass\n",
    "from pyspark.sql import SparkSession\n",
    "from utilities import SEED\n",
    "from utilities import PA2Test\n",
    "from utilities import PA2Data\n",
    "from utilities import data_cat\n",
    "from pa2_main import PA2Executor\n",
    "import time\n",
    "if INPUT_FORMAT == 'dataframe':\n",
    "    import pyspark.ml as M\n",
    "    import pyspark.sql.functions as F\n",
    "    import pyspark.sql.types as T\n",
    "if INPUT_FORMAT == 'koalas':\n",
    "    import databricks.koalas as ks\n",
    "elif INPUT_FORMAT == 'rdd':\n",
    "    import pyspark.mllib as M\n",
    "    from pyspark.mllib.feature import Word2Vec\n",
    "    from pyspark.mllib.linalg import Vectors\n",
    "    from pyspark.mllib.linalg.distributed import RowMatrix\n",
    "\n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] = '--py-files utilities.py,assignment2.py \\\n",
    "--deploy-mode client \\\n",
    "pyspark-shell'\n",
    "\n",
    "class args:\n",
    "    review_filename = data_cat.review_filename\n",
    "    product_filename = data_cat.product_filename\n",
    "    product_processed_filename = data_cat.product_processed_filename\n",
    "    ml_features_train_filename = data_cat.ml_features_train_filename\n",
    "    ml_features_test_filename = data_cat.ml_features_test_filename\n",
    "    output_root = '/home/{}/{}-pa2/test_results'.format(getpass.getuser(), PID)\n",
    "    test_results_root = data_cat.test_results_root\n",
    "    pid = PID\n",
    "\n",
    "pa2 = PA2Executor(args, input_format=INPUT_FORMAT)\n",
    "data_io = pa2.data_io\n",
    "data_dict = pa2.data_dict\n",
    "begin = time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-26T20:45:52.353249Z",
     "start_time": "2020-01-26T20:45:52.343036Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import your own dependencies\n",
    "\n",
    "\n",
    "#-----------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Bring the part_1 datasets to memory and de-cache part_2 datasets. \n",
    "# Execute this once before you start working on this Part\n",
    "data_dict, _ = data_io.cache_switch(data_dict, 'part_1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "# Task0: warm up \n",
    "This task is provided for you to get familiar with Spark API. We will use the dataframe API to demonstrate. Solution is given to you and this task won't be graded.\n",
    "\n",
    "Refer to https://spark.apache.org/docs/latest/api/python/pyspark.sql.html for API guide.\n",
    "\n",
    "The task is to implement the function below. Given the ```product_data``` table:\n",
    "1. Take and print five rows.\n",
    "\n",
    "1. Select only the ```asin``` column, then print five rows of it.\n",
    "\n",
    "1. Select the row where ```asin = B00I8KEOTM``` and print it.\n",
    "\n",
    "1. Count the total number of rows.\n",
    "\n",
    "1. Calculate the mean ```price```.\n",
    "\n",
    "1. You need to conduct the above operations, then extract some statistics out of the generated columns. You need to put the statistics in a python dictionary named ```res```. The description and schema of it are as follows:\n",
    "    ```\n",
    "    res\n",
    "     | -- count_total: int -- count of total rows of the entire table after your operations\n",
    "     | -- mean_price: float -- mean value of column price\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-26T20:45:52.368918Z",
     "start_time": "2020-01-26T20:45:52.355018Z"
    }
   },
   "outputs": [],
   "source": [
    "def task_0(data_io, product_data):\n",
    "    # -----------------------------Column names--------------------------------\n",
    "    # Inputs:\n",
    "    asin_column = 'asin'\n",
    "    overall_column = 'overall'\n",
    "    # Outputs:\n",
    "    mean_rating_column = 'meanRating'\n",
    "    count_rating_column = 'countRating'\n",
    "    # -------------------------------------------------------------------------\n",
    "\n",
    "    # ---------------------- Your implementation begins------------------------\n",
    "\n",
    "    product_data.show(5)\n",
    "    product_data[['asin']].show(5)\n",
    "    product_data.where(F.col('asin') == 'B00I8KEOTM').show()\n",
    "    count_rows = product_data.count()\n",
    "    mean_price = product_data.select(F.avg(F.col('price'))).head()[0]\n",
    "    # -------------------------------------------------------------------------\n",
    "\n",
    "    # ---------------------- Put results in res dict --------------------------\n",
    "    # Calculate the values programmatically. Do not change the keys and do not\n",
    "    # hard-code values in the dict. Your submission will be evaluated with\n",
    "    # different inputs.\n",
    "    # Modify the values of the following dictionary accordingly.\n",
    "    res = {'count_total': None, 'mean_price': None}\n",
    "    \n",
    "    # Modify res:\n",
    "\n",
    "    res['count_total'] = count_rows\n",
    "    res['mean_price'] = mean_price\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "\n",
    "    # ----------------------------- Do not change -----------------------------\n",
    "    return res\n",
    "    # -------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-26T20:45:54.222111Z",
     "start_time": "2020-01-26T20:45:52.370377Z"
    },
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+--------------------+--------------------+-----+--------------------+\n",
      "|      asin|           salesRank|          categories|               title|price|             related|\n",
      "+----------+--------------------+--------------------+--------------------+-----+--------------------+\n",
      "|B00I8HVV6E|{Home &amp; Kitch...|[[Home & Kitchen,...|Intelligent Desig...|27.99|{also_viewed -> [...|\n",
      "|B00I8KEOTM|                null|[[Apps for Androi...|                null| null|{also_viewed -> [...|\n",
      "|B00I8KCW4G|{Clothing -> 2233...|[[Clothing, Shoes...|eShakti Women's P...|41.95|{also_viewed -> [...|\n",
      "|B00I8JKCQW|{Clothing -> 1405...|[[Clothing, Shoes...|Lady Slimming Mid...| null|{also_viewed -> [...|\n",
      "|B00I8JKI8E|{Home &amp; Kitch...|[[Clothing, Shoes...|3 Tier Bangle Bra...|24.99|{also_viewed -> [...|\n",
      "+----------+--------------------+--------------------+--------------------+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+----------+\n",
      "|      asin|\n",
      "+----------+\n",
      "|B00I8HVV6E|\n",
      "|B00I8KEOTM|\n",
      "|B00I8KCW4G|\n",
      "|B00I8JKCQW|\n",
      "|B00I8JKI8E|\n",
      "+----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+----------+---------+--------------------+-----+-----+--------------------+\n",
      "|      asin|salesRank|          categories|title|price|             related|\n",
      "+----------+---------+--------------------+-----+-----+--------------------+\n",
      "|B00I8KEOTM|     null|[[Apps for Androi...| null| null|{also_viewed -> [...|\n",
      "+----------+---------+--------------------+-----+-----+--------------------+\n",
      "\n",
      "tests for task_0 --------------------------------------------------------------\n",
      "2/2 passed\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "if INPUT_FORMAT == 'dataframe':\n",
    "    res = task_0(data_io, data_dict['product'])\n",
    "    pa2.tests.test(res, 'task_0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "# Task1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-10T21:30:44.034299Z",
     "start_time": "2019-12-10T21:30:44.012787Z"
    }
   },
   "outputs": [],
   "source": [
    "# %load -s task_1 assignment2.py\n",
    "def task_1(data_io, review_data, product_data):\n",
    "    # -----------------------------Column names--------------------------------\n",
    "    # Inputs:\n",
    "    asin_column = 'asin'\n",
    "    overall_column = 'overall'\n",
    "    # Outputs:\n",
    "    mean_rating_column = 'meanRating'\n",
    "    count_rating_column = 'countRating'\n",
    "    # -------------------------------------------------------------------------\n",
    "\n",
    "    # ---------------------- Your implementation begins------------------------\n",
    "    ##spark = SparkSession.builder.appName(\"ProductRating\").getOrCreate()\n",
    "    \n",
    "    result1 = (product_data.join(review_data, product_data[\"asin\"]==review_data[\"asin\"], \"left_outer\").groupBy(product_data[\"asin\"]).agg(F.avg(F.col(\"overall\")).alias(\"meanRating\")))\n",
    "    #result1.show()\n",
    "    \n",
    "    result2 = (product_data.join(review_data, product_data[\"asin\"]==review_data[\"asin\"], \"left_outer\").groupBy(product_data[\"asin\"]).agg(F.when(F.count(F.col(\"overall\")) > 0, F.count(F.col(\"overall\"))).alias(\"countRating\")))\n",
    "    #result2.show()\n",
    "    \n",
    "    count_total = int(result1.count())\n",
    "    #print(\"Total Rows (including null rows):\", count_total)\n",
    "    \n",
    "    mean_meanRating = float(result1.agg(F.avg(F.col(\"meanRating\"))).collect()[0][0])\n",
    "    #print(\"mean value of meanRating: \", mean_meanRating)\n",
    "    \n",
    "    variance_meanRating = float(result1.agg(F.var_samp(F.col(\"meanRating\"))).collect()[0][0])\n",
    "    #print(\"Variance of meanRating:\", variance_meanRating)\n",
    "    \n",
    "    nullNulls_meanRating = int(result1.filter(F.col(\"meanRating\").isNull()).count())\n",
    "    #print(\"Count of nulls in meanRating:\", nullNulls_meanRating)\n",
    "    \n",
    "    mean_countRating = float(result2.agg(F.avg(F.col(\"countRating\"))).collect()[0][0])\n",
    "    #print(\"mean value of countRating: \", mean_countRating)   \n",
    "\n",
    "    variance_countRating = float(result2.agg(F.var_samp(F.col(\"countRating\"))).collect()[0][0])\n",
    "    #print(\"Variance of countRating:\", variance_countRating)\n",
    "    \n",
    "    nullNulls_countRating = int(result2.filter(F.col(\"countRating\").isNull()).count())\n",
    "    #print(\"Count of nulls in countRating:\", nullNulls_countRating)   \n",
    "    \n",
    "    \n",
    "    # -------------------------------------------------------------------------\n",
    "\n",
    "    # ---------------------- Put results in res dict --------------------------\n",
    "    # Calculate the values programmaticly. Do not change the keys and do not\n",
    "    # hard-code values in the dict. Your submission will be evaluated with\n",
    "    # different inputs.\n",
    "    # Modify the values of the following dictionary accordingly.\n",
    "    res = {\n",
    "        'count_total': None,\n",
    "        'mean_meanRating': None,\n",
    "        'variance_meanRating': None,\n",
    "        'numNulls_meanRating': None,\n",
    "        'mean_countRating': None,\n",
    "        'variance_countRating': None,\n",
    "        'numNulls_countRating': None\n",
    "    }\n",
    "    # Modify res:\n",
    "    res['count_total']=count_total\n",
    "    res['mean_meanRating']=mean_meanRating\n",
    "    res['variance_meanRating']=variance_meanRating\n",
    "    res['numNulls_meanRating']=nullNulls_meanRating\n",
    "    res['mean_countRating']=mean_countRating\n",
    "    res['variance_countRating']=variance_countRating\n",
    "    res['numNulls_countRating']=nullNulls_countRating\n",
    "\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "\n",
    "    # ----------------------------- Do not change -----------------------------\n",
    "    data_io.save(res, 'task_1')\n",
    "    ##spark.stop()\n",
    "    \n",
    "    return res\n",
    "    # -------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-09T22:19:04.214179Z",
     "start_time": "2019-12-09T22:18:39.293699Z"
    },
    "deletable": false,
    "editable": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 99:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tests for task_1 --------------------------------------------------------------\n",
      "Test 1/7 : count_total ... Pass\n",
      "Test 2/7 : mean_countRating ... Pass\n",
      "Test 3/7 : mean_meanRating ... Pass\n",
      "Test 4/7 : numNulls_countRating ... Pass\n",
      "Test 5/7 : numNulls_meanRating ... Pass\n",
      "Test 6/7 : variance_countRating ... Pass\n",
      "Test 7/7 : variance_meanRating ... Pass\n",
      "7/7 passed\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = task_1(data_io, data_dict['review'], data_dict['product'])\n",
    "pa2.tests.test(res, 'task_1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "\n",
    "# Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-10T21:31:16.942833Z",
     "start_time": "2019-12-10T21:31:16.925378Z"
    }
   },
   "outputs": [],
   "source": [
    "# %load -s task_2 assignment2.py\n",
    "def task_2(data_io, product_data):\n",
    "    # -----------------------------Column names--------------------------------\n",
    "    # Inputs:\n",
    "    salesRank_column = 'salesRank'\n",
    "    categories_column = 'categories'\n",
    "    asin_column = 'asin'\n",
    "    # Outputs:\n",
    "    category_column = 'category'\n",
    "    bestSalesCategory_column = 'bestSalesCategory'\n",
    "    bestSalesRank_column = 'bestSalesRank'\n",
    "    # -------------------------------------------------------------------------\n",
    "\n",
    "    # ---------------------- Your implementation begins------------------------\n",
    "    ##spark = SparkSession.builder.appName(\"Categories_SalesRank\").getOrCreate()\n",
    "    \n",
    "    category_withoutBlank=product_data.withColumn(\"categories\", F.when(F.col(\"categories\").getItem(0).getItem(0) == \"\", None).otherwise(F.col(\"categories\")))\n",
    "\n",
    "    category_column = (category_withoutBlank.withColumn(\"category\", F.when(F.col(\"categories\").isNotNull() & F.col(\"categories\").getItem(0).getItem(0).isNotNull() & F.col(\"categories\").getItem(0).isNotNull(), F.col(\"categories\").getItem(0).getItem(0))).select(\"category\")) \n",
    "    #category_column.show()\n",
    "    \n",
    "    category_column_check=category_column.distinct()\n",
    "    #category_column_check.show(100,truncate=False)\n",
    "    \n",
    "    test=category_column.filter(F.col(\"category\").isNotNull()).select(\"category\").distinct()\n",
    "    #test.show(100,truncate=False)\n",
    "    \n",
    "    bestSalesCategory_column=(product_data\n",
    "    .withColumn(\"bestSalesCategory\", F.when(F.map_keys(F.col(\"salesRank\")).isNotNull()&F.map_keys(F.col(\"salesRank\")).isNotNull()&F.map_keys(F.col(\"salesRank\"))[0].isNotNull(), F.map_keys(F.col(\"salesRank\"))[0]))\n",
    "    .select('bestSalesCategory'))\n",
    "    #bestSalesCategory_column.show()\n",
    "    \n",
    "\n",
    "    bestSalesRank_column=(product_data\n",
    "    .withColumn('bestSalesRank', F.when(F.map_keys(F.col(\"salesRank\")).isNotNull()&F.map_values(F.col(\"salesRank\"))[0].isNotNull(), F.map_values(F.col(\"salesRank\"))[0]))\n",
    "    .select('bestSalesRank'))\n",
    "    #bestSalesRank_column.show()\n",
    "    \n",
    "    count_total=int(category_column.count())\n",
    "    \n",
    "    mean_bestSalesRank=float(bestSalesRank_column.agg(F.avg(F.col(\"bestSalesRank\"))).collect()[0][0])\n",
    "    \n",
    "    variance_bestSalesRank=float(bestSalesRank_column.agg(F.var_samp(F.col(\"bestSalesRank\"))).collect()[0][0])\n",
    "    \n",
    "    numNulls_category = int(category_column.filter(F.col(\"category\").isNull()).count())\n",
    "    \n",
    "    countDistinct_category = int(category_column.filter(F.col(\"category\").isNotNull()).select(\"category\").distinct().count())\n",
    "    \n",
    "    numNulls_bestSalesCategory=int(bestSalesCategory_column.filter(F.col(\"bestSalesCategory\").isNull()).count())\n",
    "    \n",
    "    countDistinct_bestSalesCategory=int(bestSalesCategory_column.filter(F.col(\"bestSalesCategory\").isNotNull()).select(\"bestSalesCategory\").distinct().count())\n",
    "\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "\n",
    "    # ---------------------- Put results in res dict --------------------------\n",
    "    res = {\n",
    "        'count_total': None,\n",
    "        'mean_bestSalesRank': None,\n",
    "        'variance_bestSalesRank': None,\n",
    "        'numNulls_category': None,\n",
    "        'countDistinct_category': None,\n",
    "        'numNulls_bestSalesCategory': None,\n",
    "        'countDistinct_bestSalesCategory': None\n",
    "    }\n",
    "    # Modify res:\n",
    "    res['count_total']=count_total\n",
    "    res['mean_bestSalesRank']=mean_bestSalesRank\n",
    "    res['variance_bestSalesRank']=variance_bestSalesRank\n",
    "    res['numNulls_category']=numNulls_category\n",
    "    res['countDistinct_category']=countDistinct_category\n",
    "    res['numNulls_bestSalesCategory']=numNulls_bestSalesCategory\n",
    "    res['countDistinct_bestSalesCategory']=countDistinct_bestSalesCategory\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "\n",
    "    # ----------------------------- Do not change -----------------------------\n",
    "    data_io.save(res, 'task_2')\n",
    "    ##spark.stop()\n",
    "    \n",
    "    return res\n",
    "    # -------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-09T22:19:19.308187Z",
     "start_time": "2019-12-09T22:19:04.274345Z"
    },
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 127:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tests for task_2 --------------------------------------------------------------\n",
      "Test 1/7 : countDistinct_bestSalesCategory ... Pass\n",
      "Test 2/7 : countDistinct_category ... Pass\n",
      "Test 3/7 : count_total ... Pass\n",
      "Test 4/7 : mean_bestSalesRank ... Pass\n",
      "Test 5/7 : numNulls_bestSalesCategory ... Pass\n",
      "Test 6/7 : numNulls_category ... Pass\n",
      "Test 7/7 : variance_bestSalesRank ... Pass\n",
      "7/7 passed\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = task_2(data_io, data_dict['product'])\n",
    "pa2.tests.test(res, 'task_2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "# Task 3\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-10T21:31:26.542481Z",
     "start_time": "2019-12-10T21:31:26.525050Z"
    }
   },
   "outputs": [],
   "source": [
    "# %load -s task_3 assignment2.py\n",
    "def task_3(data_io, product_data):\n",
    "    # -----------------------------Column names--------------------------------\n",
    "    # Inputs:\n",
    "    asin_column = 'asin'\n",
    "    price_column = 'price'\n",
    "    attribute = 'also_viewed'\n",
    "    related_column = 'related'\n",
    "    # Outputs:\n",
    "    meanPriceAlsoViewed_column = 'meanPriceAlsoViewed'\n",
    "    countAlsoViewed_column = 'countAlsoViewed'\n",
    "    # -------------------------------------------------------------------------\n",
    "\n",
    "    # ---------------------- Your implementation begins------------------------\n",
    "    exploded_df = product_data.select(\"asin\", F.explode(\"related.also_viewed\").alias(\"also_viewed\"))\n",
    "    #exploded_df.show()\n",
    "    \n",
    "    price_df=product_data.select(\"asin\",\"price\")\n",
    "    #price_df.show()\n",
    "    \n",
    "    meanPriceAlsoViewed_column=(exploded_df.join(price_df, exploded_df[\"also_viewed\"]==price_df[\"asin\"],'left_outer').groupBy(exploded_df[\"asin\"]).agg(F.avg(F.col(\"price\")).alias(\"meanPriceAlsoViewed_column\")))\n",
    "    #meanPriceAlsoViewed_column.show()\n",
    "    \n",
    "    countAlsoViewed_column=(exploded_df.groupBy(exploded_df[\"asin\"]).agg(F.count(F.col(\"also_viewed\")).alias('countAlsoViewed')))\n",
    "    #countAlsoViewed_column.show()\n",
    "    \n",
    "    \n",
    "    \n",
    "    product_data_output = product_data.join(meanPriceAlsoViewed_column, [asin_column], how='left')\n",
    "    product_data_output = product_data_output.join(countAlsoViewed_column, [asin_column], how='left')\n",
    "    numNulls_meanPriceAlsoViewed=int(product_data_output.filter(F.col(\"meanPriceAlsoViewed_column\").isNull()).count())\n",
    "    #print(numNulls_meanPriceAlsoViewed)\n",
    "    numNulls_countAlsoViewed=int(product_data_output.filter(F.col('countAlsoViewed').isNull()).count())\n",
    "    #print(numNulls_countAlsoViewed)\n",
    "    \n",
    "    count_total=int(product_data_output.count())\n",
    "    #print(count_total)\n",
    "\n",
    "    \n",
    "    mean_meanPriceAlsoViewed=float(meanPriceAlsoViewed_column.agg(F.avg(F.col(\"meanPriceAlsoViewed_column\"))).collect()[0][0])\n",
    "    #print(mean_meanPriceAlsoViewed)\n",
    "    \n",
    "    variance_meanPriceAlsoViewed=float(meanPriceAlsoViewed_column.agg(F.var_samp(F.col(\"meanPriceAlsoViewed_column\"))).collect()[0][0])\n",
    "    #print(variance_meanPriceAlsoViewed)\n",
    "    \n",
    "    mean_countAlsoViewed=float(countAlsoViewed_column.agg(F.avg(F.col('countAlsoViewed'))).collect()[0][0])\n",
    "    #print(mean_countAlsoViewed)\n",
    "    \n",
    "    variance_countAlsoViewed=float(countAlsoViewed_column.agg(F.var_samp(F.col('countAlsoViewed'))).collect()[0][0])\n",
    "    #print(variance_countAlsoViewed)\n",
    "    \n",
    "    \n",
    "    # -------------------------------------------------------------------------\n",
    "\n",
    "    # ---------------------- Put results in res dict --------------------------\n",
    "    res = {\n",
    "        'count_total': None,\n",
    "        'mean_meanPriceAlsoViewed': None,\n",
    "        'variance_meanPriceAlsoViewed': None,\n",
    "        'numNulls_meanPriceAlsoViewed': None,\n",
    "        'mean_countAlsoViewed': None,\n",
    "        'variance_countAlsoViewed': None,\n",
    "        'numNulls_countAlsoViewed': None\n",
    "    }\n",
    "    # Modify res:\n",
    "    res['count_total']=count_total\n",
    "    res['mean_meanPriceAlsoViewed']=mean_meanPriceAlsoViewed\n",
    "    res['variance_meanPriceAlsoViewed']=variance_meanPriceAlsoViewed\n",
    "    res['numNulls_meanPriceAlsoViewed']=numNulls_meanPriceAlsoViewed\n",
    "    res['mean_countAlsoViewed']=mean_countAlsoViewed\n",
    "    res['variance_countAlsoViewed']=variance_countAlsoViewed\n",
    "    res['numNulls_countAlsoViewed']=numNulls_countAlsoViewed\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "\n",
    "    # ----------------------------- Do not change -----------------------------\n",
    "    data_io.save(res, 'task_3')\n",
    "\n",
    "    return res\n",
    "    # -------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-09T22:20:41.442745Z",
     "start_time": "2019-12-09T22:19:19.358780Z"
    },
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 212:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tests for task_3 --------------------------------------------------------------\n",
      "Test 1/7 : count_total ... Pass\n",
      "Test 2/7 : mean_countAlsoViewed ... Pass\n",
      "Test 3/7 : mean_meanPriceAlsoViewed ... Pass\n",
      "Test 4/7 : numNulls_countAlsoViewed ... Pass\n",
      "Test 5/7 : numNulls_meanPriceAlsoViewed ... Pass\n",
      "Test 6/7 : variance_countAlsoViewed ... Pass\n",
      "Test 7/7 : variance_meanPriceAlsoViewed ... Pass\n",
      "7/7 passed\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = task_3(data_io, data_dict['product'])\n",
    "pa2.tests.test(res, 'task_3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "# Task 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-10T21:31:39.503390Z",
     "start_time": "2019-12-10T21:31:39.484724Z"
    }
   },
   "outputs": [],
   "source": [
    "# %load -s task_4 assignment2.py\n",
    "def task_4(data_io, product_data):\n",
    "    # -----------------------------Column names--------------------------------\n",
    "    # Inputs:\n",
    "    price_column = 'price'\n",
    "    title_column = 'title'\n",
    "    # Outputs:\n",
    "    meanImputedPrice_column = 'meanImputedPrice'\n",
    "    medianImputedPrice_column = 'medianImputedPrice'\n",
    "    unknownImputedTitle_column = 'unknownImputedTitle'\n",
    "    # -------------------------------------------------------------------------\n",
    "\n",
    "    # ---------------------- Your implementation begins------------------------\n",
    "    price_column = product_data.select(F.col(\"price\").cast(\"float\"))\n",
    "    #price_column.show()\n",
    "    \n",
    "    mean_price = price_column.select(F.mean(\"price\")).collect()[0][0]\n",
    "    \n",
    "    meanImputedPrice_column = price_column.withColumn(\"meanImputedPrice\", F.when(F.col(\"price\").isNull(), mean_price).otherwise(F.col(\"price\")))\n",
    "    #meanImputedPrice_column.show()\n",
    "    \n",
    "    median_price = price_column.approxQuantile(\"price\", [0.5],0.05)[0]\n",
    "    \n",
    "    medianImputedPrice_column=price_column.withColumn(\"medianImputedPrice\", F.when(F.col(\"price\").isNull(), median_price).otherwise(F.col(\"price\")))\n",
    "    #medianImputedPrice_column.show()\n",
    "    \n",
    "    title_column=product_data.select('title')\n",
    "    #title_column.show()\n",
    "    \n",
    "    unknownImputedTitle_column = title_column.withColumn(\"unknownImputedTitle\", F.when((F.col(\"title\").isNull()) | (F.col(\"title\") == \"\"), \"unknown\").otherwise(F.col(\"title\")))\n",
    "    #unknownImputedTitle_column.show()\n",
    "\n",
    "    \n",
    "    count_total=int(meanImputedPrice_column.count())\n",
    "    #print(count_total)\n",
    "    \n",
    "    mean_meanImputedPrice=float(meanImputedPrice_column.agg(F.avg(F.col(\"meanImputedPrice\"))).collect()[0][0])\n",
    "    #print(mean_meanImputedPrice)\n",
    "\n",
    "    variance_meanImputedPrice=float(meanImputedPrice_column.agg(F.var_samp(F.col(\"meanImputedPrice\"))).collect()[0][0])\n",
    "    #print(variance_meanImputedPrice)\n",
    "    \n",
    "    numNulls_meanImputedPrice=int(meanImputedPrice_column.filter(F.col(\"meanImputedPrice\").isNull()).count())\n",
    "    #print(numNulls_meanImputedPrice)\n",
    "    \n",
    "    mean_medianImputedPrice=float(medianImputedPrice_column.agg(F.avg(F.col(\"medianImputedPrice\"))).collect()[0][0])\n",
    "    #print(mean_medianImputedPrice)\n",
    "    \n",
    "    variance_medianImputedPrice=float(medianImputedPrice_column.agg(F.var_samp(F.col(\"medianImputedPrice\"))).collect()[0][0])\n",
    "    #print(variance_medianImputedPrice)\n",
    "    \n",
    "    numNulls_medianImputedPrice=int(medianImputedPrice_column.filter(F.col(\"medianImputedPrice\").isNull()).count())\n",
    "    #print(numNulls_medianImputedPrice)\n",
    "    \n",
    "    numUnknowns_unknownImputedTitle=unknownImputedTitle_column.filter(F.col(\"unknownImputedTitle\") == \"unknown\").count()\n",
    "    #print(numUnknowns_unknownImputedTitle)\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "\n",
    "    # ---------------------- Put results in res dict --------------------------\n",
    "    res = {\n",
    "        'count_total': None,\n",
    "        'mean_meanImputedPrice': None,\n",
    "        'variance_meanImputedPrice': None,\n",
    "        'numNulls_meanImputedPrice': None,\n",
    "        'mean_medianImputedPrice': None,\n",
    "        'variance_medianImputedPrice': None,\n",
    "        'numNulls_medianImputedPrice': None,\n",
    "        'numUnknowns_unknownImputedTitle': None\n",
    "    }\n",
    "    # Modify res:\n",
    "    res['count_total']=count_total\n",
    "    res['mean_meanImputedPrice']=mean_meanImputedPrice\n",
    "    res['variance_meanImputedPrice']=variance_meanImputedPrice\n",
    "    res['numNulls_meanImputedPrice']=numNulls_meanImputedPrice\n",
    "    res['mean_medianImputedPrice']=mean_medianImputedPrice\n",
    "    res['variance_medianImputedPrice']=variance_medianImputedPrice\n",
    "    res['numNulls_medianImputedPrice']=numNulls_medianImputedPrice\n",
    "    res['numUnknowns_unknownImputedTitle']=numUnknowns_unknownImputedTitle\n",
    "\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "\n",
    "    # ----------------------------- Do not change -----------------------------\n",
    "    data_io.save(res, 'task_4')\n",
    "    return res\n",
    "    # -------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-09T22:20:47.953226Z",
     "start_time": "2019-12-09T22:20:41.523379Z"
    },
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tests for task_4 --------------------------------------------------------------\n",
      "Test 1/8 : count_total ... Pass\n",
      "Test 2/8 : mean_meanImputedPrice ... Pass\n",
      "Test 3/8 : mean_medianImputedPrice ... Pass\n",
      "Test 4/8 : numNulls_meanImputedPrice ... Pass\n",
      "Test 5/8 : numNulls_medianImputedPrice ... Pass\n",
      "Test 6/8 : numUnknowns_unknownImputedTitle ... Pass\n",
      "Test 7/8 : variance_meanImputedPrice ... Pass\n",
      "Test 8/8 : variance_medianImputedPrice ... Pass\n",
      "8/8 passed\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = task_4(data_io, data_dict['product'])\n",
    "pa2.tests.test(res, 'task_4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "# Task 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-10T21:32:29.284661Z",
     "start_time": "2019-12-10T21:32:29.267237Z"
    }
   },
   "outputs": [],
   "source": [
    "# %load -s task_5 assignment2.py\n",
    "def task_5(data_io, product_processed_data, word_0, word_1, word_2):\n",
    "    # -----------------------------Column names--------------------------------\n",
    "    # Inputs:\n",
    "    title_column = 'title'\n",
    "    # Outputs:\n",
    "    titleArray_column = 'titleArray'\n",
    "    titleVector_column = 'titleVector'\n",
    "    # -------------------------------------------------------------------------\n",
    "\n",
    "    # ---------------------- Your implementation begins------------------------\n",
    "\n",
    "    title_column=product_processed_data.select('title')\n",
    "    \n",
    "    titleArray_column=title_column.withColumn(\"titleArray\", F.split(F.lower(F.col(\"title\")), \" \"))\n",
    "    #titleArray_column.show()\n",
    "    \n",
    "    titleArray_column=titleArray_column.select(\"titleArray\")\n",
    "    #titleArray_column.show()\n",
    "    \n",
    "    product_processed_data_output=titleArray_column\n",
    "    #product_processed_data_output.show()\n",
    "    \n",
    "    word2Vec = M.feature.Word2Vec(\n",
    "    vectorSize=16,\n",
    "    minCount=100,\n",
    "    seed=102,\n",
    "    numPartitions=4,\n",
    "    inputCol=\"titleArray\",\n",
    "    outputCol=\"word2vec\")\n",
    "    \n",
    "    model = word2Vec.fit(titleArray_column)\n",
    "\n",
    "    #model.save(\"word2vec_model\")\n",
    "    \n",
    "    #model = M.feature.Word2VecModel.load(\"word2vec_model\")\n",
    "        \n",
    "    count_total=product_processed_data_output.count()\n",
    "    #print(count_total)\n",
    "    \n",
    "    size_vocabulary = model.getVectors().count()\n",
    "    #print(size_vocabulary)\n",
    "    \n",
    "    # -------------------------------------------------------------------------\n",
    "\n",
    "    # ---------------------- Put results in res dict --------------------------\n",
    "    res = {\n",
    "        'count_total': None,\n",
    "        'size_vocabulary': None,\n",
    "        'word_0_synonyms': [(None, None), ],\n",
    "        'word_1_synonyms': [(None, None), ],\n",
    "        'word_2_synonyms': [(None, None), ]\n",
    "    }\n",
    "    # Modify res:\n",
    "    res['count_total'] = product_processed_data_output.count()\n",
    "    res['size_vocabulary'] = model.getVectors().count()\n",
    "    for name, word in zip(\n",
    "        ['word_0_synonyms', 'word_1_synonyms', 'word_2_synonyms'],\n",
    "        [word_0, word_1, word_2]\n",
    "    ):\n",
    "        res[name] = model.findSynonymsArray(word, 10)\n",
    "    # -------------------------------------------------------------------------\n",
    "\n",
    "    # ----------------------------- Do not change -----------------------------\n",
    "    data_io.save(res, 'task_5')\n",
    "    return res\n",
    "    # -------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-09T22:26:05.015529Z",
     "start_time": "2019-12-09T22:20:47.999834Z"
    },
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/11/27 23:14:33 WARN InstanceBuilder$NativeBLAS: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
      "23/11/27 23:14:33 WARN InstanceBuilder$NativeBLAS: Failed to load implementation from:dev.ludovic.netlib.blas.ForeignLinkerBLAS\n",
      "tests for task_5 --------------------------------------------------------------\n",
      "Test 1/8 : count_total ... Pass\n",
      "Test 2/8 : size_vocabulary ... Pass\n",
      "Test 3/8 : word_0_synonyms-length ... Pass\n",
      "Test 4/8 : word_0_synonyms-correctness ... Pass\n",
      "Test 5/8 : word_1_synonyms-length ... Pass\n",
      "Test 6/8 : word_1_synonyms-correctness ... Pass\n",
      "Test 7/8 : word_2_synonyms-length ... Pass\n",
      "Test 8/8 : word_2_synonyms-correctness ... Pass\n",
      "5/5 passed\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = task_5(data_io, data_dict['product_processed'], 'piano', 'rice', 'laptop')\n",
    "pa2.tests.test(res, 'task_5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "# Task 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-10T21:32:39.991460Z",
     "start_time": "2019-12-10T21:32:39.974136Z"
    }
   },
   "outputs": [],
   "source": [
    "# %load -s task_6 assignment2.py\n",
    "def task_6(data_io, product_processed_data):\n",
    "    # -----------------------------Column names--------------------------------\n",
    "    # Inputs:\n",
    "    category_column = 'category'\n",
    "    # Outputs:\n",
    "    categoryIndex_column = 'categoryIndex'\n",
    "    categoryOneHot_column = 'categoryOneHot'\n",
    "    categoryPCA_column = 'categoryPCA'\n",
    "    # -------------------------------------------------------------------------    \n",
    "\n",
    "    # ---------------------- Your implementation begins------------------------\n",
    "    indexer = M.feature.StringIndexer(inputCol=\"category\", outputCol=\"categoryIndex\")\n",
    "    \n",
    "    encoder = M.feature.OneHotEncoder(inputCol=\"categoryIndex\", outputCol=\"categoryOneHot\", dropLast=False)\n",
    "    \n",
    "    pca = M.feature.PCA(k=15, inputCol=\"categoryOneHot\", outputCol=\"categoryPCA\")\n",
    "    \n",
    "    pipeline = M.Pipeline(stages=[indexer, encoder, pca])\n",
    "    \n",
    "    category_column=product_processed_data.select('category')\n",
    "    model = pipeline.fit(category_column)\n",
    "    df_transformed = model.transform(category_column)\n",
    "    #df_transformed.show()\n",
    "    \n",
    "    count_total=int(df_transformed.count())\n",
    "    #print(count_total)\n",
    "    \n",
    "    #summarizer = M.stat.Summarizer.metrics(\"mean\")\n",
    "    \n",
    "    meanVector_categoryOneHot=df_transformed.select(M.stat.Summarizer.mean(df_transformed.categoryOneHot))\n",
    "    #meanVector_categoryOneHot.show()\n",
    "    #print(type(meanVector_categoryOneHot))\n",
    "    meanVector_categoryOneHot=meanVector_categoryOneHot.collect()\n",
    "    ##meanVector_categoryOneHot=meanVector_categoryOneHot.toArray().tolist()\n",
    "    #print(meanVector_categoryOneHot)\n",
    "    #print(type(meanVector_categoryOneHot))\n",
    "    \n",
    "    list_meanVector_categoryOneHot=[]\n",
    "    for i in meanVector_categoryOneHot:\n",
    "        #print(i)\n",
    "        for j in i:\n",
    "            #print(j)\n",
    "            for z in j:\n",
    "                #print(z)\n",
    "                list_meanVector_categoryOneHot.append(float(z))\n",
    "    #print(list_meanVector_categoryOneHot)\n",
    "    #meanVector_categoryOneHot=[0.2513, 0.1523, 0.0562, 0.0525, 0.0521, 0.0463, 0.0368, 0.0356, 0.0351, 0.0287, 0.0286, 0.0285, 0.0278, 0.0275, 0.0207, 0.0182, 0.0142, 0.0124, 0.0117, 0.0115, 0.0076, 0.0073, 0.0065, 0.0052, 0.005, 0.0032, 0.0026, 0.0019, 0.0012, 0.0011, 0.0008, 0.0008, 0.0007, 0.0007, 0.0006, 0.0005, 0.0005, 0.0005, 0.0004, 0.0004, 0.0004, 0.0004, 0.0004, 0.0004, 0.0003, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
    "    \n",
    "    #common_list = [row.mean(categoryOneHot).toArray().tolist() for row in meanVector_categoryOneHot]\n",
    "    #print(common_list)\n",
    "    \n",
    "    meanVector_categoryPCA=df_transformed.select(M.stat.Summarizer.mean(df_transformed.categoryPCA))\n",
    "    #meanVector_categoryPCA.show()\n",
    "    meanVector_categoryPCA=meanVector_categoryPCA.collect()\n",
    "    #meanVector_categoryPCA=meanVector_categoryPCA.tolist()\n",
    "    #print(meanVector_categoryPCA)\n",
    "    #print(type(meanVector_categoryPCA))\n",
    "    list_meanVector_categoryPCA=[]\n",
    "    for i in meanVector_categoryPCA:\n",
    "        #print(i)\n",
    "        for j in i:\n",
    "            #print(j)\n",
    "            for z in j:\n",
    "                #print(z)\n",
    "                list_meanVector_categoryPCA.append(float(z))  \n",
    "    #print(list_meanVector_categoryPCA)\n",
    "    #meanVector_categoryPCA=[-0.15, -0.1752, 0.0165, -0.0027, 0.0334, -0.0537, 0.0099, -0.0046, 0.04, -0.0003, -0.0019, 0.0061, -0.0037, 0.0372, -0.0305]\n",
    "    \n",
    "    # -------------------------------------------------------------------------\n",
    "\n",
    "    # ---------------------- Put results in res dict --------------------------\n",
    "    res = {\n",
    "        'count_total': None,\n",
    "        'meanVector_categoryOneHot': [None, ],\n",
    "        'meanVector_categoryPCA': [None, ]\n",
    "    }\n",
    "    # Modify res:\n",
    "    res['count_total']=count_total\n",
    "    res['meanVector_categoryOneHot']=list_meanVector_categoryOneHot\n",
    "    res['meanVector_categoryPCA']=list_meanVector_categoryPCA\n",
    "\n",
    "\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "\n",
    "    # ----------------------------- Do not change -----------------------------\n",
    "    data_io.save(res, 'task_6')\n",
    "    return res\n",
    "    # -------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-09T22:29:57.717617Z",
     "start_time": "2019-12-09T22:29:51.132434Z"
    },
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/11/27 23:14:49 WARN LAPACK: Failed to load implementation from: com.github.fommil.netlib.NativeSystemLAPACK\n",
      "23/11/27 23:14:49 WARN LAPACK: Failed to load implementation from: com.github.fommil.netlib.NativeRefLAPACK\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tests for task_6 --------------------------------------------------------------\n",
      "Test 1/9 : count_total ... Pass\n",
      "Test 2/9 : meanVector_categoryOneHot-length ... Pass\n",
      "Test 3/9 : meanVector_categoryOneHot-sum ... Pass\n",
      "Test 4/9 : meanVector_categoryOneHot-mean ... Pass\n",
      "Test 5/9 : meanVector_categoryOneHot-variance ... Pass\n",
      "Test 6/9 : meanVector_categoryPCA-length ... Pass\n",
      "Test 7/9 : meanVector_categoryPCA-sum ... Pass\n",
      "Test 8/9 : meanVector_categoryPCA-mean ... Pass\n",
      "Test 9/9 : meanVector_categoryPCA-variance ... Pass\n",
      "9/9 passed\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = task_6(data_io, data_dict['product_processed'])\n",
    "pa2.tests.test(res, 'task_6')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-26T21:23:18.882119Z",
     "start_time": "2019-11-26T21:23:18.873162Z"
    },
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End to end time: 750.132972240448\n"
     ]
    }
   ],
   "source": [
    "print (\"End to end time: {}\".format(time.time()-begin))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Bring the part_2 datasets to memory and de-cache part_1 datasets.\n",
    "# Execute this once before you start working on this Part\n",
    "data_dict, _ = data_io.cache_switch(data_dict, 'part_2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def task_7(data_io, train_data, test_data):\n",
    "    \n",
    "    # ---------------------- Your implementation begins------------------------\n",
    "    features = train_data.columns[:-1] \n",
    "    target = \"overall\"\n",
    "    \n",
    "    dt_model = M.regression.DecisionTreeRegressor(featuresCol=\"features\", labelCol=target, maxDepth=5)\n",
    "    dt_model = dt_model.fit(train_data)\n",
    "    \n",
    "    predictions = dt_model.transform(test_data)\n",
    "\n",
    "    evaluator = M.evaluation.RegressionEvaluator(labelCol=target, predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "    rmse = float(evaluator.evaluate(predictions))\n",
    "    #print(rmse)\n",
    "    \n",
    "    \n",
    "    # -------------------------------------------------------------------------\n",
    "    \n",
    "    \n",
    "    # ---------------------- Put results in res dict --------------------------\n",
    "    res = {\n",
    "        'test_rmse': None\n",
    "    }\n",
    "    # Modify res:\n",
    "    res['test_rmse']=rmse\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "\n",
    "    # ----------------------------- Do not change -----------------------------\n",
    "    data_io.save(res, 'task_7')\n",
    "    return res\n",
    "    # -------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tests for task_7 --------------------------------------------------------------\n",
      "Test 1/1 : test_rmse ... Pass\n",
      "1/1 passed\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = task_7(data_io, data_dict['ml_features_train'], data_dict['ml_features_test'])\n",
    "pa2.tests.test(res, 'task_7')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def task_8(data_io, train_data, test_data):\n",
    "    \n",
    "    # ---------------------- Your implementation begins------------------------\n",
    "    new_train_data, val_data = train_data.randomSplit([0.75, 0.25], seed=42)\n",
    "    \n",
    "    features = train_data.columns[:-1]\n",
    "    target = \"overall\"\n",
    "    \n",
    "    dt_model =  M.regression.DecisionTreeRegressor(featuresCol=\"features\", labelCol=target, maxDepth=5)\n",
    "    dt_model = dt_model.fit(new_train_data)\n",
    "    predictions = dt_model.transform(val_data)\n",
    "    evaluator = M.evaluation.RegressionEvaluator(labelCol=target, predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "    valid_rmse_depth_5 = float(evaluator.evaluate(predictions))\n",
    "    #print(valid_rmse_depth_5)\n",
    "    \n",
    "    dt_model =  M.regression.DecisionTreeRegressor(featuresCol=\"features\", labelCol=target, maxDepth=7)\n",
    "    dt_model = dt_model.fit(new_train_data)\n",
    "    predictions = dt_model.transform(val_data)\n",
    "    evaluator = M.evaluation.RegressionEvaluator(labelCol=target, predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "    valid_rmse_depth_7 = float(evaluator.evaluate(predictions))\n",
    "    #print(valid_rmse_depth_7)   \n",
    "    \n",
    "    dt_model =  M.regression.DecisionTreeRegressor(featuresCol=\"features\", labelCol=target, maxDepth=9)\n",
    "    dt_model = dt_model.fit(new_train_data)\n",
    "    predictions = dt_model.transform(val_data)\n",
    "    evaluator = M.evaluation.RegressionEvaluator(labelCol=target, predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "    valid_rmse_depth_9 = float(evaluator.evaluate(predictions))\n",
    "    #print(valid_rmse_depth_9)\n",
    "    \n",
    "    dt_model =  M.regression.DecisionTreeRegressor(featuresCol=\"features\", labelCol=target, maxDepth=12)\n",
    "    dt_model = dt_model.fit(new_train_data)\n",
    "    predictions = dt_model.transform(val_data)\n",
    "    evaluator = M.evaluation.RegressionEvaluator(labelCol=target, predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "    valid_rmse_depth_12 = float(evaluator.evaluate(predictions))\n",
    "    #print(valid_rmse_depth_12)\n",
    "    \n",
    "    \n",
    "    dt_model =  M.regression.DecisionTreeRegressor(featuresCol=\"features\", labelCol=target, maxDepth=12)\n",
    "    dt_model = dt_model.fit(new_train_data)\n",
    "    predictions = dt_model.transform(test_data)\n",
    "    evaluator = M.evaluation.RegressionEvaluator(labelCol=target, predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "    test_rmse = float(evaluator.evaluate(predictions))\n",
    "    #print(test_rmse)\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    # -------------------------------------------------------------------------\n",
    "    \n",
    "    \n",
    "    # ---------------------- Put results in res dict --------------------------\n",
    "    res = {\n",
    "        'test_rmse': None,\n",
    "        'valid_rmse_depth_5': None,\n",
    "        'valid_rmse_depth_7': None,\n",
    "        'valid_rmse_depth_9': None,\n",
    "        'valid_rmse_depth_12': None,\n",
    "    }\n",
    "    # Modify res:\n",
    "    res['test_rmse']=test_rmse\n",
    "    res['valid_rmse_depth_5']=valid_rmse_depth_5\n",
    "    res['valid_rmse_depth_7']=valid_rmse_depth_7\n",
    "    res['valid_rmse_depth_9']=valid_rmse_depth_9\n",
    "    res['valid_rmse_depth_12']=valid_rmse_depth_12\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "\n",
    "    # ----------------------------- Do not change -----------------------------\n",
    "    data_io.save(res, 'task_8')\n",
    "    return res\n",
    "    # -------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tests for task_8 --------------------------------------------------------------\n",
      "Test 1/5 : test_rmse ... Pass\n",
      "Test 2/5 : valid_rmse_depth_12 ... Pass\n",
      "Test 3/5 : valid_rmse_depth_5 ... Pass\n",
      "Test 4/5 : valid_rmse_depth_7 ... Pass\n",
      "Test 5/5 : valid_rmse_depth_9 ... Pass\n",
      "5/5 passed\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = task_8(data_io, data_dict['ml_features_train'], data_dict['ml_features_test'])\n",
    "pa2.tests.test(res, 'task_8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End to end time: 1082.9223971366882\n"
     ]
    }
   ],
   "source": [
    "print (\"End to end time: {}\".format(time.time()-begin))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
